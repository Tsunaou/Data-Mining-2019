# Lab3 结果

161220096 欧阳鸿荣



## 零、数据集概况

| 数据集        | Attributes | Instances | sum    |
| ------------- | ---------- | --------- | ------ |
| breast-w      | 10         | 699       | 6990   |
| colic         | 23         | 368       | 8464   |
| credit-a      | 16         | 690       | 11040  |
| credit-g      | 21         | 1000      | 21000  |
| diabetes      | 9          | 768       | 6912   |
| hepatitis     | 20         | 155       | 3100   |
| mozilla4      | 6          | 15545     | 93270  |
| pc1           | 22         | 1109      | 24398  |
| pc5           | 39         | 17186     | 670254 |
| waveform-5000 | 41         | 5000      | 205000 |

## 一、基础方法与集成方法

### 1.breast-w 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 94.5637 % | 0.955 |
| Naïve Bayes    | 95.9943 % | 0.986 |
| SVM            | 95.7082 % | 0.964 |
| Neural Network | 95.2790 % | 0.986 |
| kNN            | 95.1359 % | 0.973 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 96.2804 % | 0.985 |
| Naïve Bayes    | 95.8512 % | 0.989 |
| SVM            | 95.4220 % | 0.973 |
| Neural Network | 95.9943 % | 0.989 |
| kNN            | 95.8512 % | 0.987 |



### 2.colic 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 85.3261 % | 0.813 |
| Naïve Bayes    | 77.9891 % | 0.842 |
| SVM            | 72.5543 % | 0.670 |
| Neural Network | 80.4348 % | 0.857 |
| kNN            | 81.25   % | 0.802 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 85.5978 % | 0.864 |
| Naïve Bayes    | 77.9891 % | 0.842 |
| SVM            | 69.5652 % | 0.692 |
| Neural Network | 84.5109 % | 0.876 |
| kNN            | 81.25   % | 0.824 |

### 3.credit-a 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 86.087  % | 0.887 |
| Naïve Bayes    | 77.6812 % | 0.896 |
| SVM            | 55.5072 % | 0.513 |
| Neural Network | 83.6232 % | 0.895 |
| kNN            | 81.1594 % | 0.808 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 86.8116 % | 0.928 |
| Naïve Bayes    | 77.8261 % | 0.896 |
| SVM            | 55.7971 % | 0.535 |
| Neural Network | 85.0725 % | 0.908 |
| kNN            | 81.3043 % | 0.886 |

### 4.credit-g 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 70.5    % | 0.639 |
| Naïve Bayes    | 75.4    % | 0.787 |
| SVM            | 68.7    % | 0.491 |
| Neural Network | 71.5    % | 0.730 |
| kNN            | 72      % | 0.660 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 73.3    % | 0.753 |
| Naïve Bayes    | 74.8    % | 0.787 |
| SVM            | 68.6    % | 0.490 |
| Neural Network | 76.1    % | 0.776 |
| kNN            | 72.1    % | 0.694 |

### 5.diabetes 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 73.8281 % | 0.751 |
| Naïve Bayes    | 76.3021 % | 0.819 |
| SVM            | 65.1042 % | 0.500 |
| Neural Network | 75.3906 % | 0.793 |
| kNN            | 70.1823 % | 0.650 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 74.6094 % | 0.798 |
| Naïve Bayes    | 76.5625 % | 0.817 |
| SVM            | 65.1042 % | 0.500 |
| Neural Network | 76.8229 % | 0.822 |
| kNN            | 71.0938 % | 0.725 |

### 6.hepatitis 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 83.871  % | 0.708 |
| Naïve Bayes    | 84.5161 % | 0.860 |
| SVM            | 79.3548 % | 0.500 |
| Neural Network | 80      % | 0.823 |
| kNN            | 80.6452 % | 0.653 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 83.871  % | 0.865 |
| Naïve Bayes    | 85.8065 % | 0.890 |
| SVM            | 79.3548 % | 0.492 |
| Neural Network | 84.5161 % | 0.846 |
| kNN            | 81.2903 % | 0.782 |

### 7.mozilla4 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 94.7958 % | 0.954 |
| Naïve Bayes    | 68.6394 % | 0.829 |
| SVM            | 69.54   % | 0.537 |
| Neural Network | 91.1869 % | 0.940 |
| kNN            | 88.9932 % | 0.877 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 95.111  % | 0.976 |
| Naïve Bayes    | 68.7424 % | 0.830 |
| SVM            | 69.8231 % | 0.549 |
| Neural Network | 91.2834 % | 0.945 |
| kNN            | 88.8582 % | 0.928 |

### 8.pc1 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 93.3273 % | 0.668 |
| Naïve Bayes    | 89.1794 % | 0.650 |
| SVM            | 93.5077 % | 0.563 |
| Neural Network | 93.5978 % | 0.723 |
| kNN            | 92.0649 % | 0.740 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 93.5978 % | 0.855 |
| Naïve Bayes    | 88.9089 % | 0.628 |
| SVM            | 93.8683 % | 0.574 |
| Neural Network | 93.3273 % | 0.835 |
| kNN            | 91.073  % | 0.793 |

### 9.pc5 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 97.4631 % | 0.817 |
| Naïve Bayes    | 96.4157 % | 0.833 |
| SVM            | 97.2536 % | 0.548 |
| Neural Network | 97.1023 % | 0.941 |
| kNN            | 97.2943 % | 0.932 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 97.5271 % | 0.959 |
| Naïve Bayes    | 96.4797 % | 0.845 |
| SVM            | 97.2187 % | 0.552 |
| Neural Network | 97.3118 % | 0.954 |
| kNN            | 97.37   % | 0.953 |

### 10.waveform-5000 数据集

**(a) 未使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 75.08   % | 0.830 |
| Naïve Bayes    | 80      % | 0.956 |
| SVM            | 86.42   % | 0.898 |
| Neural Network | 83.56   % | 0.963 |
| kNN            | 73.62   % | 0.802 |

**(b) 使用 Bagging**

| 方法           | 准确率    | ROC   |
| -------------- | --------- | ----- |
| J4.8 (C4.5)    | 81.2    % | 0.949 |
| Naïve Bayes    | 79.98   % | 0.956 |
| SVM            | 86.02   % | 0.939 |
| Neural Network | 85.68   % | 0.969 |
| kNN            | 74.46   % | 0.900 |



## 二、对SVM的思考与优化

上述可以发现，SVM在大多数情况下表现并不是很好，经过测试后，发现数据归一化对于其他方法影响不大，而对于SVM影响较大，因此在这里针对归一化标准化的数据SVM进行单独对比。

### 1.未bagging

| 数据集        | 准确率    | 旧数据 | ROC   | 旧数据 |
| ------------- | --------- | ------ | ----- | ------ |
| breast-w      | 96.7096 % |        | 0.965 |        |
| colic         | 84.2391 % |        | 0.813 |        |
| credit-a      | 85.5072 % |        | 0.862 |        |
| credit-g      | 72%       |        | 0.546 |        |
| diabetes      | 76.9531 % |        | 0.704 |        |
| hepatitis     | 80.6452 % |        | 0.589 |        |
| mozilla4      | 84.992  % |        | 0.848 |        |
| pc1           | 93.5077 % |        | 0.563 |        |
| pc5           | 97.0441 % |        | 0.513 |        |
| waveform-5000 | 86.02   % |        | 0.895 |        |

### 2.bagging

| 数据集        | 准确率    | 旧数据 | ROC   | 旧数据 |
| ------------- | --------- | ------ | ----- | ------ |
| breast-w      | 96.7096 % |        | 0.972 |        |
| colic         | 84.2391 % |        | 0.856 |        |
| credit-a      | 85.5072 % |        | 0.863 |        |
| credit-g      | 73 %      |        | 0.692 |        |
| diabetes      | 76.0417 % |        | 0.732 |        |
| hepatitis     | 81.9355 % |        | 0.770 |        |
| mozilla4      | 84.9148 % |        | 0.861 |        |
| pc1           | 93.8683 % |        | 0.574 |        |
| pc5           | 97.0499 % |        | 0.528 |        |
| waveform-5000 | 86.02   % |        | 0.939 |        |



## 三、对kNN算法的优化

考虑到数据集的规模和准确率，这里对credit-g  数据集进行调优，根据Weka中的默认值，对照基本结果如下：

|           | 准确率    | ROC   |
| --------- | --------- | ----- |
| 未Bagging | 72      % | 0.660 |
| Bagging   | 72.1    % | 0.694 |

根据经验，Bagging集成学习的效果大多数情况下会提高，因此优化过程中，我们的最优方案是选取Bagging进行优化。但是在调参阶段，暂时先使用速度快的一般算法。

### 1.调整距离函数（false）

Weka中的kNN默认使用的是欧氏距离，因此我们考虑使用不同距离函数来调优
| 距离函数            | 准确率    | ROC   |
| ------------------- | --------- | ----- |
| Euclidean distance  | 72      % | 0.660 |
| Chebyshev distance. | 70.2    % | 0.522 |
| FilteredDistance    | 62.3    % | 0.552 |
| Manhattan distance  | 70.3    % | 0.641 |
| Minkowski distance  | 72      % | 0.660 |

### 2.调整k值（false）

Weka中的kNN默认k值是1，基于上文中的结果，采用默认的欧式距离，调整K值，观察实验结果。

| k值  | 准确率    | ROC   |
| ---- | --------- | ----- |
| 1    | 72      % | 0.660 |
| 2    | 72.3    % | 0.669 |
| 3    | 73.3    % | 0.690 |
| 4    | 74.5    % | 0.718 |
| 5    | 74.2    % | 0.727 |
| 6    | 74.3    % | 0.734 |
| 7    | 74      % | 0.735 |
| 8    | 74.3    % | 0.741 |
| 9    | 74.3    % | 0.743 |
| 10   | 74      % | 0.745 |
| 20   | 73      % | 0.754 |

### 3.调整

可以看出，当k值在5附近时，准确率达到较高水平，因此我们选取k=4继续优化。

